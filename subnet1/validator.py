import logging
import random
import base64
import time
import datetime
from typing import Any, Dict, List, Optional
from collections import defaultdict
import os
import binascii
import uuid
import sys
import asyncio

# Import t·ª´ SDK Moderntensor (ƒë√£ c√†i ƒë·∫∑t)
try:
    from moderntensor.mt_aptos.consensus.node import ValidatorNode
    from moderntensor.mt_aptos.core.datatypes import TaskAssignment, MinerResult, ValidatorScore, ValidatorInfo, MinerInfo
    # Import successful, use real classes
    USING_MOCK_CLASSES = False
    logging.info("‚úÖ Successfully imported ValidatorNode and core datatypes from SDK")
except ImportError as e:
    logging.error(f"Could not import ValidatorNode or core datatypes from the SDK: {e}. "
                  "Ensure the 'moderntensor' SDK is installed.")
    # L·ªõp gi·∫£ ƒë·ªÉ tr√°nh l·ªói n·∫øu import th·∫•t b·∫°i
    class ValidatorNode:
        def __init__(self, *args, **kwargs):
             self.validator_scores = {}
             self.results_received = defaultdict(list)
             self.tasks_sent = {}
             self.info = type('obj', (object,), {'uid': 'fake_validator_uid'})()
        def _create_task_data(self, miner_uid: str) -> Any: return None
        # X√≥a score_miner_results gi·∫£ l·∫≠p
    class TaskAssignment: 
        def __init__(self, task_id, miner_uid, task_data):
            self.task_id = task_id
            self.miner_uid = miner_uid
            self.task_data = task_data
    class MinerResult: 
        def __init__(self, task_id, miner_uid, result_data):
            self.task_id = task_id
            self.miner_uid = miner_uid
            self.result_data = result_data
    class ValidatorScore: pass
    class ValidatorInfo: 
        def __init__(self, uid, **kwargs):
            self.uid = uid
    class MinerInfo: 
        def __init__(self, uid, **kwargs):
            self.uid = uid
    USING_MOCK_CLASSES = True

# Import t·ª´ c√°c module trong subnet n√†y
try:
    from .scoring.clip_scorer import calculate_clip_score
except ImportError:
    logging.error("Could not import scoring functions from .scoring.clip_scorer.")
    def calculate_clip_score(*args, **kwargs) -> float: return 0.0

logger = logging.getLogger(__name__)

DEFAULT_PROMPTS = [
    "A photorealistic image of an astronaut riding a horse on the moon.",
    "A watercolor painting of a cozy bookstore cafe in autumn.",
    "A synthwave style cityscape at sunset.",
    "A macro shot of a bee collecting pollen from a sunflower.",
    "A fantasy landscape with floating islands and waterfalls.",
    "A cute dog wearing sunglasses and a party hat.",
    "Impressionist painting of a Parisian street scene.",
    "A steaming bowl of ramen noodles with detailed ingredients.",
    "Cyberpunk warrior standing in a neon-lit alley.",
    "A tranquil zen garden with raked sand and stones.",
]

class Subnet1Validator(ValidatorNode):
    """
    Validator cho Subnet 1 (Image Generation).
    K·∫ø th·ª´a ValidatorNode v√† tri·ªÉn khai logic t·∫°o task, ch·∫•m ƒëi·ªÉm ·∫£nh.
    """

    def __init__(self, *args, **kwargs):
        """Kh·ªüi t·∫°o ValidatorNode v√† c√°c thu·ªôc t√≠nh ri√™ng c·ªßa Subnet 1."""
        # Extract api_port if provided
        self.api_port = kwargs.pop('api_port', None)
        
        super().__init__(*args, **kwargs)
        
        # Set reference to self in core for subnet-specific scoring access
        self.core.validator_instance = self
        
        logger.info(f"‚ú® [bold]Subnet1Validator[/] initialized for UID: [cyan]{self.info.uid[:10]}...[/]")
        # Th√™m c√°c kh·ªüi t·∫°o kh√°c n·∫øu c·∫ßn, v√≠ d·ª•:
        # self.image_generation_model = self._load_model()
        # self.clip_scorer = self._load_clip_scorer()

    # --- 1. Override ph∆∞∆°ng th·ª©c t·∫°o Task Data ---
    def _create_task_data(self, miner_uid: str) -> Any:
        """
        T·∫°o d·ªØ li·ªáu task (prompt) ƒë·ªÉ g·ª≠i cho miner.
        *** ƒê√£ c·∫≠p nh·∫≠t ƒë·ªÉ th√™m validator_endpoint ***

        Args:
            miner_uid (str): UID c·ªßa miner s·∫Ω nh·∫≠n task (c√≥ th·ªÉ d√πng ƒë·ªÉ t√πy bi·∫øn task).

        Returns:
            Any: D·ªØ li·ªáu task, trong tr∆∞·ªùng h·ª£p n√†y l√† dict ch·ª©a prompt v√† validator_endpoint.
                 C·∫•u tr√∫c n√†y c·∫ßn ƒë∆∞·ª£c miner hi·ªÉu.
        """
        selected_prompt = random.choice(DEFAULT_PROMPTS)
        logger.debug(f"Creating task for miner {miner_uid} with prompt: '{selected_prompt}'")

        # L·∫•y API endpoint c·ªßa ch√≠nh validator n√†y t·ª´ self.info
        # C·∫ßn ƒë·∫£m b·∫£o self.info v√† self.info.api_endpoint ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o ƒë√∫ng
        origin_validator_endpoint = getattr(self.info, 'api_endpoint', None)
        if not origin_validator_endpoint:
             # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p endpoint kh√¥ng c√≥ s·∫µn (quan tr·ªçng)
             logger.error(f"Validator {getattr(self.info, 'uid', 'UNKNOWN')} has no api_endpoint configured in self.info. Cannot create task properly.")
             # C√≥ th·ªÉ tr·∫£ v·ªÅ None ho·∫∑c raise l·ªói ƒë·ªÉ ngƒÉn g·ª≠i task kh√¥ng ƒë√∫ng
             return None # Ho·∫∑c raise ValueError("Validator endpoint missing")

        # T·∫°o deadline v√≠ d·ª• (v√≠ d·ª•: 5 ph√∫t k·ªÉ t·ª´ b√¢y gi·ªù)
        now = datetime.datetime.now(datetime.timezone.utc)
        deadline_dt = now + datetime.timedelta(minutes=5)
        deadline_str = deadline_dt.isoformat()

        # ƒê·∫∑t priority m·∫∑c ƒë·ªãnh
        priority_level = random.randint(1, 5)

        # Tr·∫£ v·ªÅ dictionary ch·ª©a c√°c tr∆∞·ªùng c·∫ßn thi·∫øt CHO MINER HI·ªÇU
        # Miner s·∫Ω c·∫ßn ƒë·ªçc 'description' ƒë·ªÉ l·∫•y prompt
        # Miner s·∫Ω c·∫ßn ƒë·ªçc 'validator_endpoint' ƒë·ªÉ bi·∫øt g·ª≠i k·∫øt qu·∫£ v·ªÅ ƒë√¢u
        return {
            "description": selected_prompt, # Prompt ch√≠nh l√† description c·ªßa task
            "deadline": deadline_str,
            "priority": priority_level,
            "validator_endpoint": origin_validator_endpoint # <<<--- TH√äM D√íNG N√ÄY
        }

    # --- Restore the correct override method for scoring ---
    def _score_individual_result(self, task_data: Any, result_data: Any) -> float:
        """
        (Override) Ch·∫•m ƒëi·ªÉm cho m·ªôt k·∫øt qu·∫£ c·ª• th·ªÉ t·ª´ miner cho Subnet 1.
        This method is called by the base ValidatorNode class during its scoring phase.

        Args:
            task_data: D·ªØ li·ªáu c·ªßa task ƒë√£ g·ª≠i (dict ch·ª©a 'description' l√† prompt).
            result_data: D·ªØ li·ªáu k·∫øt qu·∫£ miner tr·∫£ v·ªÅ (dict ch·ª©a 'output_description', etc.).

        Returns:
            ƒêi·ªÉm s·ªë float t·ª´ 0.0 ƒë·∫øn 1.0.
        """
        logger.debug(f"üíØ Scoring result via _score_individual_result...")
        score = 0.0 # Default score
        start_score_time = time.time()
        try:
            # 1. Extract prompt and base64 image
            if not isinstance(task_data, dict) or "description" not in task_data:
                 logger.warning(f"Scoring failed: Task data is not a dict or missing 'description'. Task data: {str(task_data)[:100]}...")
                 return 0.0
            original_prompt = task_data["description"]

            if not isinstance(result_data, dict):
                logger.warning(f"Scoring failed: Received result_data is not a dictionary. Data: {str(result_data)[:100]}...")
                return 0.0
            image_base64 = result_data.get("output_description")
            reported_error = result_data.get("error_details")
            processing_time_ms = result_data.get("processing_time_ms", 0) # Optional

            # 2. Check for errors or missing image
            if reported_error:
                logger.warning(f"Miner reported an error: '{reported_error}'. Assigning score 0.")
                return 0.0
            if not image_base64 or not isinstance(image_base64, str):
                logger.warning(f"No valid image data (base64 string) found in result_data. Assigning score 0. Data: {str(result_data)[:100]}...")
                return 0.0

            # 3. Decode image and Save it
            try:
                image_bytes = base64.b64decode(image_base64)

                # --- Start: Save Image Logic ---
                output_dir = "result_image"
                try:
                    os.makedirs(output_dir, exist_ok=True)
                    # Using placeholder name for now, ideally pass task_id here.
                    miner_uid = result_data.get("miner_uid", "unknown_miner")
                    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S_%f")
                    # Need task_id for a truly unique name. Placeholder:
                    filename = f"{output_dir}/result_{miner_uid[:8]}_{timestamp}.png"
                    with open(filename, "wb") as f:
                        f.write(image_bytes)
                    logger.info(f"   Saved image result to: {filename}")
                except OSError as file_err:
                    logger.error(f"   Error saving image file to {filename}: {file_err}")
                except Exception as e:
                    logger.exception(f"   Unexpected error saving image: {e}")
                # --- End: Save Image Logic ---

            except (binascii.Error, ValueError, TypeError) as decode_err:
                 logger.error(f"Scoring failed: Invalid base64 data received. Error: {decode_err}. Assigning score 0.")
                 return 0.0 # Return 0 if decode fails

            # 4. Calculate the actual score using CLIP
            try:
                score = calculate_clip_score(prompt=original_prompt, image_bytes=image_bytes)
                score = max(0.0, min(1.0, score)) # Ensure score is [0, 1]
                logger.info(f"   Calculated score using CLIP: [bold yellow]{score:.4f}[/] (Processing: {processing_time_ms}ms)")
            except ImportError:
                 logger.error("calculate_clip_score function is not available. Assigning score 0.")
                 score = 0.0
            except Exception as clip_err:
                logger.exception(f"Error during CLIP score calculation: {clip_err}. Assigning score 0.")
                score = 0.0

            # Return the calculated score
            scoring_duration = time.time() - start_score_time
            logger.debug(f"üèÅ Finished scoring process in {scoring_duration:.4f}s. Final score: [bold yellow]{score:.4f}[/]")
            return score

        except Exception as e:
            logger.exception(f"üí• Unexpected error during scoring preparation: {e}. Assigning score 0.")
            return 0.0

    # --- KH√îNG C√íN PH∆Ø∆†NG TH·ª®C score_miner_results ·ªû ƒê√ÇY ---

    # C√°c ph∆∞∆°ng th·ª©c kh√°c c·ªßa ValidatorNode ƒë∆∞·ª£c k·∫ø th·ª´a v√† s·ª≠ d·ª•ng logic m·ªõi.

    def _should_process_result(self, result: MinerResult) -> bool:
        """Ki·ªÉm tra xem k·∫øt qu·∫£ t·ª´ miner c√≥ h·ª£p l·ªá ƒë·ªÉ x·ª≠ l√Ω kh√¥ng."""
        logger.debug(f"üïµÔ∏è Checking validity of result for task '{result.task_id}' from miner '{result.miner_uid[:10]}...'")
        # Ki·ªÉm tra c·∫•u tr√∫c result_data m·ªõi
        if not isinstance(result.result_data, dict) or "output_description" not in result.result_data:
            logger.warning(f"‚ö†Ô∏è Invalid result format for task '{result.task_id}' from miner '{result.miner_uid[:10]}...'. Missing 'output_description' in result_data.")
            return False
        logger.debug(f"‚úÖ Result for task '{result.task_id}' seems valid structure-wise.")
        return True

    def _generate_task_assignment(self, miner: 'MinerInfo') -> Optional['TaskAssignment']:
        """T·∫°o nhi·ªám v·ª• c·ª• th·ªÉ cho miner (v√≠ d·ª•: t·∫°o prompt sinh ·∫£nh)."""
        # T·∫°o m·ªôt task_id duy nh·∫•t
        task_id = self._generate_unique_task_id(miner.uid)
        logger.info(f"üìù Generating task '{task_id}' for miner '{miner.uid[:10]}...'")

        # T·∫°o task_data c·ª• th·ªÉ cho Subnet 1 (v√≠ d·ª•: prompt)
        try:
            prompt = self._generate_random_prompt()
            # Create task_data dict with 'description' key for the prompt
            # to match what the miner expects inside task_data
            task_data = {"description": prompt}
            logger.info(f"   Generated prompt: [italic green]'{prompt}'[/] for task '{task_id}'")

            assignment = TaskAssignment(
                task_id=task_id,
                miner_uid=miner.uid,
                task_data=task_data, # Assign the dict with 'description' key
                # Ensure TaskModel used by validator logic populates correctly
            )
            return assignment
        except Exception as e:
            logger.exception(f"üí• Error generating task data for miner '{miner.uid[:10]}...': {e}")
            return None

    def _generate_unique_task_id(self, miner_uid: str) -> str:
        """Generate unique task ID for a miner."""
        return f"task_{miner_uid[:8]}_{int(time.time())}_{uuid.uuid4().hex[:8]}"

    # --- C√°c h√†m helper t√πy ch·ªçn cho Subnet 1 --- 

    def _generate_random_prompt(self) -> str:
        """T·∫°o prompt ng·∫´u nhi√™n cho nhi·ªám v·ª• sinh ·∫£nh."""
        prompts = [
            "A photorealistic image of a cat wearing a wizard hat",
            "A watercolor painting of a futuristic city skyline at sunset",
            "A cute robot reading a book in a cozy library, digital art",
            "Impressionist painting of a sunflower field under a stormy sky",
            "A steaming cup of coffee on a wooden table, macro shot",
            "Pencil sketch of an ancient dragon sleeping on a pile of gold",
        ]
        return random.choice(prompts)

    # def _load_model(self):
    #     """T·∫£i model sinh ·∫£nh (v√≠ d·ª•: Stable Diffusion)."""
    #     logger.info("Loading image generation model...")
    #     # ... logic t·∫£i model ...
    #     logger.info("Image generation model loaded.")
    #     # return model

    # def _load_clip_scorer(self):
    #     """T·∫£i model ch·∫•m ƒëi·ªÉm CLIP."""
    #     logger.info("Loading CLIP scorer...")
    #     # ... logic t·∫£i clip ...
    #     logger.info("CLIP scorer loaded.")
    #     # return scorer

    # def _decode_image(self, base64_string):
    #     """Gi·∫£i m√£ ·∫£nh t·ª´ chu·ªói base64."""
    #     # ... logic gi·∫£i m√£ ...
    #     # return image_object

    # === Main run method for backward compatibility ===
    async def run(self):
        """
        Main run method for backward compatibility.
        
        This method provides backward compatibility with existing validator scripts
        that expect a run() method on the validator instance.
        """
        logger.info(f"üöÄ Starting Subnet1Validator run method for UID: {self.info.uid}")
        
        try:
            # Use the new modular ValidatorNode interface with correct port
            await self.start(api_port=self.api_port)
            logger.info(f"‚úÖ Subnet1Validator started successfully")
            
            # Run until interrupted
            try:
                while True:
                    await asyncio.sleep(1)
            except KeyboardInterrupt:
                logger.info(f"üëã Subnet1Validator stopped by user")
                
        except Exception as e:
            logger.error(f"‚ùå Subnet1Validator run error: {e}")
            raise
        finally:
            await self.shutdown()
            logger.info(f"üèÅ Subnet1Validator run method finished")